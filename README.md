# Writer_Classifier_URFU_NNandCV

1. Постановка задачи:

Предложенная задача по определению автора на основе написанного текста подразумевает под собой задачу многоклассовой классификации. 
Для решения представленной задачи потребуется решить задачу обработки естественного языка (NLP). 
Попытаться решить эту задачу можно, как минимум, 3 способами*: 
- С помощью применения трансформеров
- С помощью применения простой нейронной сети
- С помощью применения рекуррентных нейронных сетей

*В данной работе будут рассмотрены 2 способа - применение предобученных токенизатора и модели трансформера из библиотеки HuggingFace, а также применение нейронной сети, написанной на базе библиотеки torch модуля nn и TfIdf векторайзера из библиотеки sklearn.

2. БЛОК 1. Изучение данных:

- Обращаемся к архиву со всеми предложенными файлами. 
- Видим 6 файлов вида "Фамилия писателя".txt, каждый из которых содержит тексты соответствующих писателей, что представляет собой обучающую выборку для наших моделей, 1 пример ответа в формате .csv и 21 файл в формате .txt с неизвестным авторами - наша тестовая выборка.
-  Создаем общий словарь с обучающими и тестовыми данными, чтобы оценить содержимое. Нам интересен язык и соотношение количества текста для обучения и для тестирования. 
- Видим, что данные представлены на русском языке. Разделяем словарь на train и test и посмотрим размерность. После чего изобразим распределение данных.
- Видим сильное (посимвольное) превалирование обучающих данных.

3. БЛОК 2. Обработка данных:

- Рассмотрели 2 подхода - подать полные тексты и разделить на подтексты. Вариант с полными текстами не очень подходит, поскольку, по сути, будет лишь по 1 примеру для каждого автора. Стандартными методами разделить на train и valid не выйдет по этой же причине.
- Разделим массивные обучающие тексты на подтексты, чтобы увеличить количество примеров каждого класса для обучения будущей модели и чтобы была возможность корректно разделить случайным образом на валидационную и тренировочную выборки.
- Изучив данные, несложно заметить, что обучающие данные местами разделены двумя и более переносом строк. Воспользуемся этим свойством для разделения на полноценные предложения и абзацы.
- Удаляем все нерусские символы (на случай, если встречается другой язык, как в "Войне и Мир", например).

4. БЛОК 3. Подготовка данных и дообучение модели из библиотеки Transformers:

- Создаем обучающий и валидационный датасеты с помощью библиотеки datasets от HuggingFace.
- Выбираем модель и токенайзер, обученные на текстках на русском языке. Среди рассмотренных были модели 'DeepPavlov/rubert-base-cased' и 'cointegrated/rubert-tiny'. Модель от DeepPavlov оказалась тяжеловата, поэтому ввиду легкости, скорости и довольно хорошей точности модели rubert-tiny - выбор пал в пользу последней.
- Создаем функцию токенизации, чтобы применить ее через метод map() ко всему датасету.
- Создаем функцию подсчета метрик для последующей передачи в TrainingArguments.
- Создаем TrainingArguments и Trainer для обучения модели. Запускаем процесс обучения.
- Из логов достаем необходимые нам данные для построения графика функции потерь и точности.
- Из графика видим, что примерно с 3 эпохи начинается процесс переобучения. Благодаря параметру "load_best_model_at_end=True" мы автоматически сохраняем лучшую модель, а дальнейшее обучение, как показала практика изменения гиперпараметров (learning_rate и weight_decay), нецелесообразно. 
- Делаем предсказание на тестовых данных и сохраняем в файл "Transformers_predictions.csv".

5. БЛОК 4. Подготовка данных и обучение модели нейронной сети с применением модуля nn библиотеки torch и tfidfvectorizer'а от sklearn:

- Подготавливаем данные для последующей векторизации.
- Векторизированные данные переводим в тензоры и создаем DataLoader'ы.
- Создаем архитектуру модели. 
- Инициализируем модель, определяем функцию потерь и оптимизатор.
- Проводим обучение и валидацию с выводом результатов.
- Строим график функции потерь и точности. Видим, что уже после 3 эпохи модель начала переобучаться. Изменение количества отключаемых нейронов в Dropout и добавление Batchnorm1d картину не меняет.
- Делаем предсказания на тестовом датасете.

6. БЛОК 5. Сравнение предсказания трансформера и нейронной сети:

- По метрике "Accuracy" модель на основе трансформера показала результат около 85%, нейронная сеть - 80%
- Объединив полученные предсказания в один датасет, видим, что по большей части текстов предсказания совпадают.

7. Предложения по улучшению результатов для решения поставленной задачи:

- Дополнительно можно было бы рассмотреть вариант с применением рекуррентной нейронной сети (LSTM, например).
- Для улучшения качества предсказаний модели на основе трансформеров можно попробовать взять более тяжелые модели (например, приведенный вариант от DeepPavlov), если позволяют ресурсы.
- Касаемо улучшения в целом, вомзожно, стоило бы попробовать применить методы лемматизации и удаления "стоп-слов" (однако такой подход далеко не всегда гарантирует улучшение качества модели). В данной работе его не применяли, чтобы данные для обучения были максимально приближены к тестовым.
- Ввиду сильного дисбаланса классов, можно было бы попробовать применить методы по выравниванию (например, разделение текстов на равные части по символам). 
